name: DataLoader
description: Load and split data into train and validation sets from file or URL

inputs:
- {name: data-path, type: CSV, optional: true, description: 'Path to input file'}
- {name: data-url, type: String, optional: true, description: 'URL to input data'}
- {name: val-size, type: Float, default: 0.2, description: 'Validation set size (between 0 and 1)'}
- {name: output_-ormat, type: String, default: 'csv', description: 'Output format (csv/json/parquet)'}
outputs:
- {name: train_data, type: CSV, description: 'Path to train data file'}
- {name: val_data, type: CSV, description: 'Path to validation data file'} 
- {name: metadata, type: JSON, description: 'Path to metadata file'}
implementation:
  container:
    image: ravidocker189/data_loader:latest
    command: [python]
    args: [
      'src/dl_f.py',
      --val-size, {inputValue: val-size},
      --output-format, {inputValue: output-format},
      --_output_paths, {outputPath: train-data}
    ]
